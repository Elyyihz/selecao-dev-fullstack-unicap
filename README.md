
# ü§ñ Gerador de Hist√≥rias Infantis com IA

## üìñ Sobre o Projeto
Este √© um projeto **Full Stack** que utiliza o poder da **API do Google Gemini** para criar hist√≥rias infantis curtas e criativas a partir de uma simples ideia.  
O utilizador insere um tema ou uma pequena descri√ß√£o, e a aplica√ß√£o gera uma hist√≥ria √∫nica em segundos.

O objetivo √© demonstrar a integra√ß√£o entre um backend moderno em **Python (FastAPI)** e um frontend reativo em **Next.js/React**, consumindo um servi√ßo de **IA generativa** de ponta.

---

## ‚ú® Funcionalidades
- **Interface Intuitiva**: Um design limpo e amig√°vel para inserir a ideia da hist√≥ria.  
- **Gera√ß√£o por IA**: Conecta-se diretamente com a API do Google Gemini para criar conte√∫do original.  
- **Feedback Visual**: Exibe um estado de carregamento enquanto a hist√≥ria est√° a ser gerada.  
- **Tratamento de Erros**: Apresenta mensagens claras caso ocorra um problema na comunica√ß√£o com o backend.  
- **Layout Responsivo**: Funciona bem em desktops e dispositivos m√≥veis.  

---

## üõ†Ô∏è Tecnologias Utilizadas
### Backend (Servidor)
- Python 3.10+  
- FastAPI  
- Uvicorn  
- Google Generative AI SDK  
- Pydantic  
- python-dotenv  

### Frontend (Cliente)
- Next.js  
- React  
- Tailwind CSS  

---

## üèóÔ∏è Arquitetura e Decis√£o Local vs Externa
- **Frontend (Next.js/React)** roda localmente em `http://localhost:3000`.  
- **Backend (FastAPI)** roda localmente em `http://localhost:8000`.  
- A **IA escolhida** (Google Gemini) √© **externa**, acessada via API com chave privada.  
- Decis√£o: manter backend e frontend **locais** para controle de fluxo e seguran√ßa, delegando apenas a gera√ß√£o de hist√≥rias ao servi√ßo externo do Google.

---

## üöÄ Como Executar o Projeto

### Pr√©-requisitos
- **Node.js** (vers√£o 18 ou superior)  
- **Python** (vers√£o 3.8 ou superior)  
- Uma **Chave de API do Google Gemini** (obtenha no Google AI Studio)  

---

### üîπ 1. Configura√ß√£o do Backend
```bash
# Navegue para a pasta do backend
cd backend/

# Crie e ative um ambiente virtual
python -m venv venv
# No Windows:
venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate

# Instale as depend√™ncias
pip install fastapi uvicorn "google-generativeai" python-dotenv

# Crie um arquivo .env na pasta backend/ e adicione:
API_KEY="SUA_CHAVE_DA_API_DO_GOOGLE_GEMINI_AQUI"
GENERATION_MODEL="gemini-1.5-flash"

# Inicie o servidor backend
uvicorn main:app --reload
````

‚û° O backend estar√° rodando em: [http://localhost:8000](http://localhost:8000)

---

### üîπ 2. Configura√ß√£o do Frontend

```bash
# Navegue para a pasta do frontend
cd Front-End\meu-app-de-historias

# Instale as depend√™ncias
npm install

# Inicie o servidor de desenvolvimento
npm run dev
```

‚û° O frontend estar√° acess√≠vel em: [http://localhost:3000](http://localhost:3000)

Abra o navegador e comece a criar hist√≥rias! üéâ

---

## ‚öôÔ∏è Endpoint da API

**URL:** `/api/v1/analyze`
**M√©todo:** `POST`

### Corpo da Requisi√ß√£o (JSON)

```json
{
  "prompt": "Um drag√£o que tinha medo de altura."
}
```

### Resposta de Sucesso (JSON)

```json
{
  "response": "Era uma vez um jovem drag√£o chamado Fa√≠sca..."
}
```

---

## üìå Exemplos de Requisi√ß√£o via Terminal

### Usando `curl`

```bash
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Um drag√£o que tinha medo de altura."}'
```

### Usando `HTTPie`

```bash
http POST http://localhost:8000/api/v1/analyze prompt="Um drag√£o que tinha medo de altura."
```

### Usando Postman

* M√©todo: **POST**
* URL: `http://localhost:8000/api/v1/analyze`
* Body ‚Üí Raw ‚Üí JSON:

```json
{
  "prompt": "Um drag√£o que tinha medo de altura."
}
```

---

## üë§ Autor

* Desenvolvido  com amor e dedica√ß√£o por  [Elynne Lima](https://github.com/ElynneLima)
